{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***WeatherFlow: Real-time Weather Data Pipeline***\n",
    "\n",
    "### ***DS463 Data Engineering Final Project***\n",
    "\n",
    "### ***Syed Roshan Ali - 2021648***\n",
    "\n",
    "### ***Behram Khan - 2021127***\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***1. Executive Summary***\n",
    "\n",
    "\n",
    "The **WeatherFlow** project is a comprehensive end-to-end data engineering solution designed to collect, process, and analyze real-time weather data from multiple sources. This project demonstrates the application of modern data engineering concepts including data ingestion, streaming, processing, storage, and visualization.\n",
    "\n",
    "The system integrates several key technologies:\n",
    "\n",
    "- **Apache Kafka** for real-time data streaming\n",
    "\n",
    "- **Apache Spark** for distributed data processing\n",
    "\n",
    "- **Apache Airflow** for workflow orchestration\n",
    "\n",
    "- **PostgreSQL** for structured data storage\n",
    "\n",
    "- **Docker** for containerization and deployment\n",
    "\n",
    "- **Flask/Dash** for interactive data visualization\n",
    "\n",
    "This report provides a comprehensive overview of the project implementation, architecture, and results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***2. Problem Statement***\n",
    "\n",
    "\n",
    "Weather data is critical for numerous applications including agriculture, transportation, urban planning, and emergency management. However, raw weather data often comes from diverse sources in varying formats, update frequencies, and quality levels. This creates several challenges:\n",
    "\n",
    "1. **Data Fragmentation:** Weather data is scattered across multiple providers (OpenWeatherMap, WeatherAPI, weather stations) with different formats and access methods.\n",
    "\n",
    "2. **Real-time Processing Requirements:** For many applications such as emergency response and transportation, weather data needs to be processed and analyzed in near real-time.\n",
    "\n",
    "3. **Data Reliability and Quality:** Weather data can contain inconsistencies, missing values, or errors that need to be identified and addressed.\n",
    "\n",
    "4. **Scalability Challenges:** Weather data collection and processing needs to scale efficiently across hundreds of locations and multiple data sources.\n",
    "\n",
    "The WeatherFlow project aims to create a comprehensive data engineering solution to collect, process, and analyze weather data from multiple sources in real-time, addressing these challenges by building a robust, scalable pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***3. Architecture Overview***\n",
    "\n",
    "\n",
    "The WeatherFlow system is built with a modern data engineering architecture that includes:\n",
    "\n",
    "### ***Data Flow***\n",
    "\n",
    "1. **Data Ingestion**: Python scripts fetch data from weather APIs (OpenWeatherMap and WeatherAPI)\n",
    "\n",
    "2. **Data Streaming**: Kafka streams the data in real-time between components\n",
    "\n",
    "3. **Data Processing**: Apache Spark processes and analyzes the weather data\n",
    "\n",
    "4. **Workflow Orchestration**: Apache Airflow schedules and monitors the entire pipeline\n",
    "\n",
    "5. **Data Storage**: Files are stored in a data lake architecture (raw and processed zones)\n",
    "\n",
    "6. **Visualization**: Interactive Flask dashboard visualizes insights\n",
    "\n",
    "### ***Technology Stack***\n",
    "\n",
    "- **Languages**: Python, SQL, Bash\n",
    "\n",
    "- **Frameworks**: Apache Spark, Apache Kafka, Apache Airflow, Flask/Dash\n",
    "\n",
    "- **Storage**: File-based storage with a data lake structure and PostgreSQL\n",
    "\n",
    "- **Containerization**: Docker with Docker Compose for easy deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***4. Workflow Orchestration with Apache Airflow***\n",
    "\n",
    "Apache Airflow is used for workflow orchestration in the WeatherFlow project. It schedules and monitors the entire data pipeline, ensuring that all components work together seamlessly.\n",
    "\n",
    "### ***4.1 Airflow Weather Pipeline***\n",
    "\n",
    "The Airflow DAG (Directed Acyclic Graph) for the weather pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Airflow Weather Pipeline](/Users/syedroshanalishah/Documents/DE/2021648_2021127_DS463_Final/PROJECT_SS_VIDEOS_DEMO/Screenshots/airflow_weather_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***5. Docker Infrastructure***\n",
    "\n",
    "The entire WeatherFlow system is containerized using Docker, allowing for easy deployment and scalability. The Docker infrastructure includes multiple services that work together to form the complete data pipeline.\n",
    "\n",
    "### ***Docker Dashboard***\n",
    "\n",
    "\n",
    "- The Docker Dashboard showing the running container for the **DS463 final project** with 18.84% CPU usage.\n",
    "\n",
    "- Memory consumption metrics indicate 1.97GB used out of 3.74GB allocated.\n",
    "\n",
    "- The container has been running for 1 hour without interruptions.\n",
    "\n",
    "- This demonstrates the stable containerized deployment of the WeatherFlow system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Docker Dashboard](/Users/syedroshanalishah/Documents/DE/2021648_2021127_DS463_Final/PROJECT_SS_VIDEOS_DEMO/Screenshots/docker_dashboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Docker Image Layers***\n",
    "\n",
    "The Docker images are built with multiple layers to optimize build time and resource usage:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Docker Image Layers](/Users/syedroshanalishah/Documents/DE/2021648_2021127_DS463_Final/PROJECT_SS_VIDEOS_DEMO/Screenshots/docker_image_layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Docker Container***\n",
    "\n",
    "\n",
    "- Docker Desktop showing all containers for the WeatherFlow project including PostgreSQL, Spark master, Spark worker, Kafka, Airflow, and dashboard services.\n",
    "\n",
    "- Each container is running with its own configuration and logs visible, demonstrating the microservices architecture of the system.\n",
    "\n",
    "- The Spark master and worker containers show successful initialization with messages about the Bitnami Spark container startup.\n",
    "\n",
    "- PostgreSQL database is properly initialized and listening on port 5432, providing data storage for the application.\n",
    "\n",
    "- All essential services (Kafka, Spark, PostgreSQL, Airflow, dashboard) are running simultaneously, showing the complete data pipeline in action.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Docker Container Logs](/Users/syedroshanalishah/Documents/DE/2021648_2021127_DS463_Final/PROJECT_SS_VIDEOS_DEMO/Screenshots/docker_container_logs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ***6. Data Ingestion and Streaming***\n",
    "\n",
    "### ***6.1 Weather API Integration***\n",
    "\n",
    "The system fetches weather data from multiple sources:\n",
    "\n",
    "- **WeatherAPI**: Primary data source (API key: 1f5800c837ab40bfbe2161243251305)\n",
    "\n",
    "- **OpenWeatherMap API**: Secondary data source\n",
    "\n",
    "- **Simulated Weather Station Data**: For testing and development\n",
    "\n",
    "### ***6.2 Kafka Streaming***\n",
    "\n",
    "Apache Kafka serves as the central messaging system for the WeatherFlow project, enabling real-time data streaming between components. The Kafka infrastructure consists of:\n",
    "\n",
    "- Kafka brokers for message handling\n",
    "\n",
    "- Zookeeper for coordination\n",
    "\n",
    "- Producers that send weather data to Kafka topics\n",
    "\n",
    "- Consumers that process the streamed data\n",
    "\n",
    "#### ***Kafka Cluster Overview***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Kafka Cluster Overview](/Users/syedroshanalishah/Documents/DE/2021648_2021127_DS463_Final/PROJECT_SS_VIDEOS_DEMO/Screenshots/kafka_cluster_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Sending Messages Through Kafka***\n",
    "\n",
    "\n",
    "- Terminal output showing successful Kafka messaging workflow: first sending a test message to the \"weather-raw-data\" topic, then the consumer service processing and saving weather data for multiple cities.\n",
    "\n",
    "- The logs demonstrate the complete data flow from producer to consumer, with weather data for Berlin, Tokyo, and Mexico City being received, processed, and saved to the appropriate directories with timestamps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sending Messages Through Kafka](/Users/syedroshanalishah/Documents/DE/2021648_2021127_DS463_Final/PROJECT_SS_VIDEOS_DEMO/Screenshots/Sending_message_through_Kafka.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ***7. Data Processing with Apache Spark***\n",
    "\n",
    "Apache Spark is used for distributed data processing in the WeatherFlow project. The Spark infrastructure consists of:\n",
    "\n",
    "- A Spark master node for coordination\n",
    "\n",
    "- Spark worker nodes for distributed processing\n",
    "\n",
    "- PySpark applications for data transformation and analysis\n",
    "\n",
    "### ***7.1 Spark Master UI***\n",
    "\n",
    "The Spark Master UI provides an overview of the Spark cluster and running applications:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Spark Master UI](/Users/syedroshanalishah/Documents/DE/2021648_2021127_DS463_Final/PROJECT_SS_VIDEOS_DEMO/Screenshots/SPARK_UI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***7.2 Spark Worker API Response***\n",
    "\n",
    "\n",
    "- Terminal output showing the Spark worker API response from a curl request to the Spark worker endpoint.\n",
    "\n",
    "- The JSON response confirms the Spark worker is in \"ALIVE\" state with ID \"worker-20250523214931-172.19.0.6-39431\".\n",
    "\n",
    "- Resource allocation shows 1 core available with 1024MB memory, with 0 cores and 0 memory currently in use.\n",
    "\n",
    "- The worker is accessible via web interface at \"http://172.19.0.6:8081\", enabling monitoring and management.\n",
    "\n",
    "- System shows 1 active worker in the Spark cluster, ready to process distributed data processing tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Spark Worker API Response](/Users/syedroshanalishah/Documents/DE/2021648_2021127_DS463_Final/PROJECT_SS_VIDEOS_DEMO/Screenshots/Spark_worker_api_response.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***8. Data Storage with PostgreSQL***\n",
    "\n",
    "PostgreSQL is used for structured data storage in the WeatherFlow project. It stores processed weather data and provides a foundation for complex queries and analytics.\n",
    "\n",
    "### ***8.1 PostgreSQL Query Results***\n",
    "\n",
    "The screenshot below shows the results of a PostgreSQL query on weather data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PostgreSQL Query Results](/Users/syedroshanalishah/Documents/DE/2021648_2021127_DS463_Final/PROJECT_SS_VIDEOS_DEMO/Screenshots/postgres_query_results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***9. Data Visualization***\n",
    "\n",
    "The WeatherFlow project includes an interactive dashboard built with Flask and Dash for visualizing weather data. The dashboard provides real-time insights into weather conditions across multiple locations.\n",
    "\n",
    "### ***9.1 Weather Dashboard - Current Conditions***\n",
    "\n",
    "The dashboard shows current weather conditions for multiple cities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Weather Dashboard - Current Conditions](/Users/syedroshanalishah/Documents/DE/2021648_2021127_DS463_Final/PROJECT_SS_VIDEOS_DEMO/Screenshots/weather_dashboard_current_conditions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ***10. Key Features and Capabilities***\n",
    "\n",
    "The WeatherFlow system provides several key features and capabilities:\n",
    "\n",
    "### ***10.1 Real-time Data Processing***\n",
    "\n",
    "- Ingests data from multiple weather APIs in real-time\n",
    "\n",
    "- Processes and transforms data using Kafka and Spark\n",
    "\n",
    "- Updates the dashboard with the latest weather information\n",
    "\n",
    "### ***10.2 Scalable Architecture***\n",
    "\n",
    "- Containerized with Docker for easy deployment and scaling\n",
    "\n",
    "- Distributed processing with Apache Spark\n",
    "\n",
    "- Message-based architecture with Apache Kafka\n",
    "\n",
    "### ***10.3 Comprehensive Monitoring***\n",
    "\n",
    "- Docker container monitoring\n",
    "\n",
    "- Kafka topic monitoring\n",
    "\n",
    "- Spark job monitoring\n",
    "\n",
    "- Airflow workflow monitoring\n",
    "\n",
    "### ***10.4 Interactive Visualization***\n",
    "\n",
    "- Real-time weather dashboard\n",
    "\n",
    "- Interactive charts and graphs\n",
    "\n",
    "- Filtering and exploration capabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ***11. Running the WeatherFlow System***\n",
    "\n",
    "### ***11.1 Prerequisites***\n",
    "\n",
    "- Docker and Docker Compose\n",
    "\n",
    "- Python 3.8+\n",
    "\n",
    "- WeatherAPI key (already configured: 1f5800c837ab40bfbe2161243251305)\n",
    "\n",
    "- OpenWeatherMap API key (optional)\n",
    "\n",
    "### ***11.2 Starting the System***\n",
    "\n",
    "\n",
    "- Navigate to the docker directory\n",
    "- cd weather_flow/docker\n",
    "\n",
    "- tart all services\n",
    "- docker-compose up -d \n",
    "\n",
    "### ***11.3 Accessing Components***\n",
    "- **Dashboard**: http://localhost:8051\n",
    "\n",
    "- **Airflow UI**: http://localhost:8091 (username: admin, password: admin)\n",
    "\n",
    "- **Kafka UI** (Kafdrop): http://localhost:9000\n",
    "\n",
    "- **Spark Master UI**: http://localhost:8081\n",
    "\n",
    "### ***11.4 Verifying Components***\n",
    "\n",
    "- View Kafka producer logs\n",
    "- docker logs weather-producer\n",
    "\n",
    "- View Kafka consumer logs\n",
    "- docker logs weather-consumer\n",
    "\n",
    "- Check PostgreSQL connection\n",
    "- docker exec postgres psql -U airflow -d airflow -c \"SELECT version();\"\n",
    "\n",
    "- Check Spark version\n",
    "- docker exec spark-master spark-submit --version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ***12. Conclusion***\n",
    "\n",
    "The WeatherFlow project demonstrates a comprehensive approach to building a real-time data engineering pipeline. By integrating multiple technologies (Kafka, Spark, Airflow, PostgreSQL, Docker, and Flask), the system provides a robust solution for collecting, processing, and visualizing weather data.\n",
    "\n",
    "The project showcases several key data engineering concepts:\n",
    "\n",
    "- Real-time data ingestion and streaming\n",
    "\n",
    "- Distributed data processing\n",
    "\n",
    "- Workflow orchestration\n",
    "\n",
    "- Containerization and deployment\n",
    "\n",
    "- Interactive data visualization\n",
    "\n",
    "The modular architecture of the system allows for easy extension and scaling, making it suitable for handling larger volumes of data and additional data sources in the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***14. References***\n",
    "\n",
    "- 1. Apache Kafka Documentation: https://kafka.apache.org/documentation/\n",
    "- 2. Apache Spark Documentation: https://spark.apache.org/docs/latest/\n",
    "- 3. Apache Airflow Documentation: https://airflow.apache.org/docs/\n",
    "- 4. Flask Documentation: https://flask.palletsprojects.com/\n",
    "- 5. Dash Documentation: https://dash.plotly.com/\n",
    "- 6. Docker Documentation: https://docs.docker.com/\n",
    "- 7. WeatherAPI Documentation: https://www.weatherapi.com/docs/\n",
    "- 8. OpenWeatherMap API Documentation: https://openweathermap.org/api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***15. Acknowledgments***\n",
    "\n",
    "We would like to acknowledge the following open-source projects and resources that made this project possible:\n",
    "\n",
    "- Apache Kafka, Spark, and Airflow communities\n",
    "\n",
    "- Docker and Docker Compose\n",
    "\n",
    "- Python and its ecosystem of libraries\n",
    "\n",
    "- WeatherAPI and OpenWeatherMap for providing weather data APIs\n",
    "\n",
    "- Flask and Dash for visualization capabilities\n",
    "\n",
    "Special thanks to our instructors and peers for their guidance throughout the development of this project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
